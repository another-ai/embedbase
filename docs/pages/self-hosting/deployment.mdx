import Image from 'next/image'

# Deploying Embedbase

For any help or assistance with deployment, [book a demo](https://cal.com/potato/20min) and we will help you deploy your own instance.

- [Using Postgres](#using-postgres)
- [Using Supabase](#using-supabase)

First, install Embedbase Python package and [Uvicorn](https://www.uvicorn.org/) to run it:

```bash copy
pip install embedbase uvicorn
```

## Using Postgres

Run Postgres in Docker:

```bash copy
docker run --name postgres -e POSTGRES_DB=embedbase -e POSTGRES_PASSWORD=localdb -p 5432:5432 -p 8080:8080 -d ankane/pgvector
```

Basic entrypoint that uses Postgres & OpenAI ([get your key](https://platform.openai.com/account/api-keys)):

```py filename="main.py" copy
import os
from embedbase import get_app
from embedbase.database.postgres_db import Postgres
from embedbase.embedding.openai import OpenAI

app = get_app().use_db(Postgres()).use_embedder(OpenAI("<your key>")).run()
```

Run:

```bash copy
uvicorn main:app
```

## Using Supabase

Basic entrypoint that uses Supabase & OpenAI ([get your key](https://platform.openai.com/account/api-keys)):

```py filename="main.py" copy
import os
from embedbase import get_app
from embedbase.database.supabase_db import Supabase
from embedbase.embedding.openai import OpenAI

app = get_app().use_db(Supabase("<your url>", "<your key>")).use_embedder(OpenAI("<your key>")).run()
```

There are multiple ways to use Supabase, either [running it locally](https://supabase.com/docs/guides/cli/local-development) or using their hosted instance.

First, create a supabase project on https://supabase.com.

### Setting up Supabase

First, follow this [guide](https://docs.embedbase.xyz/self-hosting/setting-up-supabase) to setup Supabase.

ðŸŽ‰ Now you should be able to run Embedbase with Supabase

```bash
uvicorn main:app
```

## Additional information

If you are wondering where the `1536`comes from, it is the dimension of the vector generated by [OpenAI technology (embeddings)](https://platform.openai.com/docs/guides/embeddings), if you use something else, such as cohere.ai it would be 4096. Currently we only support OpenAI to build embeddings but you can easily implement another system, check [customisation](https://docs.embedbase.xyz/self-hosting/customisation#custom-embedder).

## Deploy on Render.com

 You can find the instructions [here](https://docs.embedbase.xyz/tutorials/self-host-on-render).

## Cloud Run deployment

Embedbase makes it easy for you to deploy your own instance. This assures you're in control of your data end to end.

### Setup

```bash
# login to gcloud
gcloud auth login

PROJECT_ID=$(gcloud config get-value project)

# Enable container registry
gcloud services enable containerregistry.googleapis.com

# Enable Cloud Run
gcloud services enable run.googleapis.com

# Enable Secret Manager
gcloud services enable secretmanager.googleapis.com

# create a secret for the config
gcloud secrets create EMBEDBASE --replication-policy=automatic

# add a secret version based on your yaml config
gcloud secrets versions add EMBEDBASE --data-file=config.yaml

IMAGE_URL="gcr.io/${PROJECT_ID}/embedbase:0.0.1"

docker buildx build . --platform linux/amd64 -t ${IMAGE_URL} -f ./docker/Dockerfile

docker push ${IMAGE_URL}

gcloud run deploy embedbase \
  --image ${IMAGE_URL} \
  --region us-central1 \
  --allow-unauthenticated \
  --set-secrets /secrets/config.yaml=EMBEDBASE:1

# getting cloud run url
gcloud run services list --platform managed --region us-central1 --format="value(status.url)" --filter="metadata.name=embedbase"
```

If you don't want to use Google Cloud Run, consider:
- https://fly.io/
- https://deta.space/

